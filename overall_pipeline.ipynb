{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking Pipeline for DroneAudioset dataset\n",
    "### We perform: beamforming, spectral gating, MPSeNet-based noise suppression and SSLAM-based audio classification steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize imports\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from numpy import matlib\n",
    "import soundfile as sf\n",
    "import noisereduce as nr #type: ignore\n",
    "from speechbrain.processing.features import STFT, ISTFT # type: ignore\n",
    "from speechbrain.processing.multi_mic import Covariance, Mvdr # type: ignore\n",
    "\n",
    "# specific to memory profile/computation\n",
    "from memory_profiler import memory_usage #type: ignore\n",
    "import time\n",
    "import psutil\n",
    "# %load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen Setting:\n",
      "Volume: 80pc\n",
      "Room: room1\n",
      "Drone: drone1\n",
      "Drone-Speaker Distance: speaker-dist-1m\n",
      "Mic: mic3_8array-up\n",
      "Drone-Mic Distance: mic-dist-25cm\n",
      "File List: ['mic3_8array-up-File1.wav', 'mic3_8array-up-File2.wav', 'mic3_8array-up-File3.wav', 'mic3_8array-up-File4.wav', 'mic3_8array-up-File5.wav', 'mic3_8array-up-File6.wav']\n"
     ]
    }
   ],
   "source": [
    "# initalize param\n",
    "ROOT_PATH = '/data/BlindDroneData/ComputeResourcesCheck/'\n",
    "fs = 16000\n",
    "# chosen setting\n",
    "volume = '80pc'\n",
    "room = 'room1'\n",
    "drone = 'drone1'\n",
    "speaker_dist = 'speaker-dist-1m'\n",
    "mic_dist = 'mic-dist-25cm'\n",
    "throttle = 'throttle-100'\n",
    "mic = 'mic3_8array-up'\n",
    "file_list = [f'{mic}-File{idx}.wav' for idx in range(1, 7)]\n",
    "\n",
    "print('Chosen Setting:')\n",
    "print(f'Volume: {volume}\\nRoom: {room}\\nDrone: {drone}\\nDrone-Speaker Distance: {speaker_dist}')\n",
    "print(f'Mic: {mic}\\nDrone-Mic Distance: {mic_dist}')\n",
    "print(f'File List: {file_list}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function definitions\n",
    "# === Microphone array geometry (2D circular) ===\n",
    "def circular_array_positions(radius, num_mics, reorder_idx_list):\n",
    "    angles = np.linspace(0, 2 * np.pi, num_mics, endpoint=False)\n",
    "    mic_positions = torch.zeros((num_mics,3), dtype=torch.float)\n",
    "    x = radius * np.cos(angles)\n",
    "    y = radius * np.sin(angles)\n",
    "    z = np.zeros_like(x)\n",
    "    for idx, reorder_idx in enumerate(reorder_idx_list):\n",
    "        mic_positions[idx, :] = torch.FloatTensor([x[reorder_idx], y[reorder_idx], z[reorder_idx]])\n",
    "    return mic_positions\n",
    "\n",
    "def cartesian_to_azimuth_elevation(cartesian_coord_list):\n",
    "    cartesian_coord_list = cartesian_coord_list.detach().cpu().numpy()\n",
    "    x,y,z = cartesian_coord_list\n",
    "    # Compute azimuth in radians\n",
    "    azimuth = np.arctan2(y, x)\n",
    "    # Compute elevation in radians\n",
    "    elevation = np.arctan2(z, np.sqrt(x**2 + y**2))\n",
    "    # Convert radians to degrees\n",
    "    azimuth_deg = np.degrees(azimuth)\n",
    "    elevation_deg = np.degrees(elevation)\n",
    "    return azimuth_deg, elevation_deg\n",
    "\n",
    "# read single channel audio files\n",
    "def read_audio_signal(file_path, fs, always_2d=True):\n",
    "    sig, sig_fs = sf.read(file_path, dtype='float32', always_2d=always_2d)\n",
    "    assert sig_fs == fs\n",
    "    return sig\n",
    "\n",
    "# write audio signals, including multi-channel\n",
    "def write_audio_signal(file_path, sig, fs):\n",
    "\tsf.write(file=file_path, data=sig, samplerate=fs)\n",
    "\n",
    "# return the direction of arrival [x,y,z] in meters\n",
    "def compute_doa_from_location(speaker_str, mic_str, mic_name_str, num_windows,\n",
    "                              z_drone=1.5, z_src=0.485):\n",
    "    x_mic = 0; y_mic = 0\n",
    "    z_drone_to_mic = int(mic_str.split('-')[-1][:-2])/100. # convert to meters\n",
    "    if 'down' in mic_name_str:\n",
    "        z_mic = z_drone - z_drone_to_mic\n",
    "    elif 'up' in mic_name_str:\n",
    "        z_mic = z_drone + z_drone_to_mic\n",
    "    else:\n",
    "        print(f'Incorrect mic type: {mic_name_str}')\n",
    "    x_src = -int(speaker_str.split('-')[-1][:-1])/1.414\n",
    "    y_src = x_src\n",
    "    doa = np.array([x_src-x_mic, y_src-y_mic, z_src-z_mic])\n",
    "    azim, _ = cartesian_to_azimuth_elevation(torch.tensor(doa, dtype=torch.float32))\n",
    "    # current data collection fixes the azimuth at 135 degrees\n",
    "    assert np.abs(azim+135) < 1e-5, \"Wrong azimuth value!\"\n",
    "    doas = matlib.repmat(doa, m=num_windows, n=1)\n",
    "    doas = torch.tensor(doas, dtype=torch.float32)\n",
    "    doas = doas.unsqueeze(0)\n",
    "    return doas\n",
    "\n",
    "def profile_code(code_func, *args, **kwargs):\n",
    "    start_time = time.time()\n",
    "    cpu_before = psutil.cpu_percent(interval=None)\n",
    "    mem_usage = memory_usage((code_func, args, kwargs), max_usage=True)\n",
    "    cpu_after = psutil.cpu_percent(interval=None)\n",
    "    end_time = time.time()\n",
    "    print('='*50)\n",
    "    print(f\"Execution Time: {end_time - start_time:.2f} sec\")\n",
    "    print(f\"CPU Usage: {cpu_after - cpu_before:.2f}%\")\n",
    "    print(f\"Max Memory Usage: {mem_usage} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MVDR Beamforming (using SpeechBrain Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize parameters for beamforming\n",
    "N_MICS = 8\n",
    "# MIC_ANGLE_VECTOR = np.array([270, 225, 0, 135, 315, 180, 45, 90])\n",
    "MIC_DIAMETER = 0.5 # 0.3 for drone2, 0.5 for drone1\n",
    "reorder_idx_list = np.array([6, 5, 0, 3, 7, 4, 1, 2])\n",
    "MIC_GEOMETRY = circular_array_positions(MIC_DIAMETER/2, N_MICS, reorder_idx_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.5924e-17, -2.5000e-01,  0.0000e+00],\n",
       "        [-1.7678e-01, -1.7678e-01,  0.0000e+00],\n",
       "        [ 2.5000e-01,  0.0000e+00,  0.0000e+00],\n",
       "        [-1.7678e-01,  1.7678e-01,  0.0000e+00],\n",
       "        [ 1.7678e-01, -1.7678e-01,  0.0000e+00],\n",
       "        [-2.5000e-01,  3.0616e-17,  0.0000e+00],\n",
       "        [ 1.7678e-01,  1.7678e-01,  0.0000e+00],\n",
       "        [ 1.5308e-17,  2.5000e-01,  0.0000e+00]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MIC_GEOMETRY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing MVDR Beamforming using SpeechBrain\n",
      "File: mic3_8array-up-File1.wav\n",
      "File: mic3_8array-up-File2.wav\n",
      "File: mic3_8array-up-File3.wav\n",
      "File: mic3_8array-up-File4.wav\n",
      "File: mic3_8array-up-File5.wav\n",
      "File: mic3_8array-up-File6.wav\n",
      "==================================================\n",
      "Execution Time: 85.48 sec\n",
      "CPU Usage: 12.40%\n",
      "Max Memory Usage: 19955.25 MB\n"
     ]
    }
   ],
   "source": [
    "def perform_beamforming():\n",
    "    # read each file, perform mvdr beamforming\n",
    "    print('Performing MVDR Beamforming using SpeechBrain')\n",
    "    for file_name in file_list:\n",
    "        print(f'File: {file_name}')\n",
    "        audio_path = os.path.join(ROOT_PATH, 'preprocessed-audio', 'drone-with-source-recordings', file_name)\n",
    "        noise_path = os.path.join(ROOT_PATH, 'preprocessed-audio', 'drone-only-recordings', file_name)\n",
    "        # === Load multichannel audio ===\n",
    "        audio_sig_orig = read_audio_signal(audio_path, fs)\n",
    "        audio_sig = torch.tensor(audio_sig_orig, dtype=torch.float32) # convert to tensor\n",
    "        audio_sig = audio_sig.unsqueeze(0) # dim: [1, time, channels]\n",
    "        # === Load multichannel noise ===\n",
    "        noise_sig_orig = read_audio_signal(noise_path, fs)\n",
    "        # retain only a small sample noise -- taking samples in the middle to model stationary noise\n",
    "        noise_sig_orig = noise_sig_orig[(30*fs):(40*fs), :] \n",
    "        noise_sig = torch.tensor(noise_sig_orig, dtype=torch.float32)\n",
    "        noise_sig = noise_sig.unsqueeze(0)\n",
    "        # === initialize modules ===\n",
    "        stft = STFT(sample_rate=fs, n_fft=2048)\n",
    "        cov = Covariance()\n",
    "        istft = ISTFT(sample_rate=fs, n_fft=2048)\n",
    "        mvdr = Mvdr()\n",
    "        # === compute STFT and Covariance ===\n",
    "        Xs = stft(audio_sig)\n",
    "        Ns = stft(noise_sig)\n",
    "        NNs = cov(Ns)\n",
    "        # == match the number of time steps across noise and audio\n",
    "        audio_time_steps = Xs.shape[1]\n",
    "        noise_time_steps = NNs.shape[1]\n",
    "        if noise_time_steps < audio_time_steps:\n",
    "            num_repeats = (audio_time_steps // noise_time_steps) + 1\n",
    "            NNs_repeated = NNs.repeat(1, num_repeats, 1, 1, 1)\n",
    "            NNs_repeated = NNs_repeated[:, :audio_time_steps, :, :, :]\n",
    "        assert Xs.shape[1] == NNs_repeated.shape[1], \"Incompatible time steps!\"\n",
    "        # compute DOA from source location\n",
    "        doas = compute_doa_from_location(speaker_str=speaker_dist,\n",
    "                                        mic_str=mic_dist,\n",
    "                                        mic_name_str=mic,\n",
    "                                        num_windows=Xs.shape[1])\n",
    "        # compute MVDR and obtain the beamformed signal\n",
    "        Ys_mvdr = mvdr(Xs, NNs_repeated, doas, doa_mode=True, mics=MIC_GEOMETRY, fs=fs)\n",
    "        beamformed_sig = istft(Ys_mvdr)\n",
    "        bf_folder = os.path.join(ROOT_PATH, 'beamforming')\n",
    "        os.makedirs(bf_folder, exist_ok=True)\n",
    "        save_path = os.path.join(bf_folder, f'mvdr-{file_name}')\n",
    "        write_audio_signal(save_path, beamformed_sig[0,:,0], fs)\n",
    "\n",
    "profile_code(perform_beamforming)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectral Gating (using NoiseReduce Library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize parameters for Spectral Gating\n",
    "aggressiveness = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing Spectral Gating using NoiseReduce\n",
      "File: mic3_8array-up-File1.wav\n",
      "File: mic3_8array-up-File2.wav\n",
      "File: mic3_8array-up-File3.wav\n",
      "File: mic3_8array-up-File4.wav\n",
      "File: mic3_8array-up-File5.wav\n",
      "File: mic3_8array-up-File6.wav\n",
      "==================================================\n",
      "Execution Time: 5.03 sec\n",
      "CPU Usage: -2.00%\n",
      "Max Memory Usage: 780.51171875 MB\n"
     ]
    }
   ],
   "source": [
    "# %%memit\n",
    "def perform_spectral_gating():\n",
    "    print('Performing Spectral Gating using NoiseReduce')\n",
    "    for file_name in file_list:\n",
    "        print(f'File: {file_name}')\n",
    "        bf_path = os.path.join(ROOT_PATH, 'beamforming', f'mvdr-{file_name}')\n",
    "        bf_sig = read_audio_signal(bf_path, fs)\n",
    "        assert bf_sig.shape[1] == 1\n",
    "        nr_sig = nr.reduce_noise(y=bf_sig[:,0], sr=fs, stationary=False, \n",
    "                                    thresh_n_mult_nonstationary=aggressiveness)\n",
    "        # save audio\n",
    "        nr_folder = os.path.join(ROOT_PATH, 'spectral-gating')\n",
    "        os.makedirs(nr_folder, exist_ok=True)\n",
    "        save_path = os.path.join(nr_folder, f'nr-{file_name}-agg{aggressiveness}.wav')\n",
    "        write_audio_signal(save_path, nr_sig, fs)\n",
    "profile_code(perform_spectral_gating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed May 21 13:48:38 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 545.23.08              Driver Version: 545.23.08    CUDA Version: 12.3     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3090        On  | 00000000:1A:00.0 Off |                  N/A |\n",
      "| 30%   28C    P8              13W / 350W |     58MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA GeForce RTX 3090        On  | 00000000:68:00.0 Off |                  N/A |\n",
      "| 30%   30C    P8              11W / 350W |    647MiB / 24576MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      1772      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A      2251      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A     68862      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A   1402439      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    0   N/A  N/A   2563710      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "|    1   N/A  N/A      1772      G   /usr/lib/xorg/Xorg                           35MiB |\n",
      "|    1   N/A  N/A      2251      G   /usr/lib/xorg/Xorg                           35MiB |\n",
      "|    1   N/A  N/A     68862      G   /usr/lib/xorg/Xorg                          107MiB |\n",
      "|    1   N/A  N/A     70151      G   gnome-control-center                          4MiB |\n",
      "|    1   N/A  N/A   1402439      G   /usr/lib/xorg/Xorg                           36MiB |\n",
      "|    1   N/A  N/A   1403516      G   /usr/lib/firefox/firefox                      0MiB |\n",
      "|    1   N/A  N/A   2563710      G   /usr/lib/xorg/Xorg                           35MiB |\n",
      "|    1   N/A  N/A   2759383      G   /usr/bin/gnome-shell                         64MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== System ===\n",
      "OS: Linux 5.15.0-119-generic\n",
      "Architecture: x86_64\n",
      "Python Version: 3.12.2\n",
      "\n",
      "=== CPU ===\n",
      "Processor: x86_64\n",
      "Physical Cores: 18\n",
      "Logical Cores: 36\n",
      "Frequency: 2905.96 MHz\n",
      "\n",
      "=== RAM ===\n",
      "Total RAM: 134.73 GB\n",
      "\n",
      "=== GPU ===\n",
      "GPU 0 - NVIDIA GeForce RTX 3090\n",
      "  Load: 0.0%\n",
      "  Memory: 58.0/24576.0 MB\n",
      "  Temperature: 28.0 °C\n",
      "GPU 1 - NVIDIA GeForce RTX 3090\n",
      "  Load: 0.0%\n",
      "  Memory: 647.0/24576.0 MB\n",
      "  Temperature: 30.0 °C\n"
     ]
    }
   ],
   "source": [
    "import platform, psutil, GPUtil\n",
    "\n",
    "print(\"=== System ===\")\n",
    "print(f\"OS: {platform.system()} {platform.release()}\")\n",
    "print(f\"Architecture: {platform.machine()}\")\n",
    "print(f\"Python Version: {platform.python_version()}\")\n",
    "\n",
    "print(\"\\n=== CPU ===\")\n",
    "print(f\"Processor: {platform.processor()}\")\n",
    "print(f\"Physical Cores: {psutil.cpu_count(logical=False)}\")\n",
    "print(f\"Logical Cores: {psutil.cpu_count(logical=True)}\")\n",
    "print(f\"Frequency: {psutil.cpu_freq().current:.2f} MHz\")\n",
    "\n",
    "print(\"\\n=== RAM ===\")\n",
    "mem = psutil.virtual_memory()\n",
    "print(f\"Total RAM: {mem.total / 1e9:.2f} GB\")\n",
    "\n",
    "print(\"\\n=== GPU ===\")\n",
    "try:\n",
    "    GPUs = GPUtil.getGPUs()\n",
    "    for gpu in GPUs:\n",
    "        print(f\"GPU {gpu.id} - {gpu.name}\")\n",
    "        print(f\"  Load: {gpu.load * 100:.1f}%\")\n",
    "        print(f\"  Memory: {gpu.memoryUsed}/{gpu.memoryTotal} MB\")\n",
    "        print(f\"  Temperature: {gpu.temperature} °C\")\n",
    "except Exception as e:\n",
    "    print(\"GPUtil not available or no GPU found:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "blind-drone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
